server:
  port: ${REWARD_CALCULATOR_PORT:8080}

reactor:
  bufferSize:
    small: ${REACTOR_BUFFER_SIZE:256}

spring:
  application:
    name: "@project.artifactId@"
    version: "@project.version@"
  jmx.enabled: true
  config:
    activate:
      on-profile: default
  cloud:
    function:
      definition: trxProcessor;trxProcessorOut;errors;trxRejectedProducer
    stream:
      bindings:
        trxProcessor-in-0:
          destination: ${KAFKA_RTD_TOPIC:rtd-trx}
          group: ${KAFKA_RTD_GROUP_ID:idpay-consumer-group}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-rtd
        trxProcessorOut-out-0:
          destination: ${KAFKA_TRANSACTION_USER_ID_SPLITTER_TOPIC:idpay-transaction-user-id-splitter}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-idpay
        trxRejectedProducer-out-0:
          destination: ${KAFKA_TRANSACTION_TOPIC:idpay-transaction}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-idpay-transaction
        errors-out-0:
          destination: ${KAFKA_ERRORS_TOPIC:idpay-errors}
          content-type: ${KAFKA_CONTENT_TYPE:application/json}
          binder: kafka-errors
      binders:
        kafka-rtd:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_RTD_BROKER:${KAFKA_BROKER:}}
              configuration:
                sasl.jaas.config: ${KAFKA_RTD_SASL_JAAS_CONFIG:}
        kafka-idpay:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_TRANSACTION_USER_ID_SPLITTER_BROKER:${KAFKA_BROKER:}}
              configuration:
                sasl.jaas.config: ${KAFKA_TRANSACTION_USER_ID_SPLITTER_SASL_JAAS_CONFIG:}
                key.serializer: org.apache.kafka.common.serialization.StringSerializer
        kafka-idpay-transaction:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_TRANSACTION_BROKER:${KAFKA_BROKER:}}
              configuration:
                sasl.jaas.config: ${KAFKA_TRANSACTION_SASL_JAAS_CONFIG:}
                key.serializer: org.apache.kafka.common.serialization.StringSerializer
        kafka-errors:
          type: kafka
          environment:
            spring.cloud.stream.kafka.binder:
              brokers: ${KAFKA_ERRORS_BROKER:${KAFKA_BROKER:}}
              configuration:
                sasl.jaas.config: ${KAFKA_ERRORS_SASL_JAAS_CONFIG:}
                key.serializer: org.apache.kafka.common.serialization.StringSerializer
      kafka:
        binder:
          auto-create-topics: false
          configuration:
            heartbeat.interval.ms: ${KAFKA_CONFIG_HEARTBEAT_INTERVAL_MS:3000}
            session.timeout.ms: ${KAFKA_CONFIG_SESSION_TIMEOUT_MS:60000}
            request.timeout.ms: ${KAFKA_CONFIG_REQUEST_TIMEOUT_MS:60000}
            sasl.mechanism: ${KAFKA_CONFIG_SASL_MECHANISM:PLAIN}
            security.protocol: ${KAFKA_CONFIG_SECURITY_PROTOCOL:SASL_SSL}
            connections.max.idle.ms: ${KAFKA_CONFIG_CONNECTION_MAX_IDLE_TIME:180000}
            metadata.max.idle.ms: ${KAFKA_CONFIG_METADATA_MAX_IDLE_MS:180000}
            metadata.max.age.ms: ${KAFKA_CONFIG_METADATA_MAX_AGE_INTERVAL:179000}
            max.request.size: ${KAFKA_CONFIG_METADATA_MAX_REQUEST_SIZE:1000000}
        bindings:
          trxProcessor-in-0:
            consumer:
              startOffset: ${KAFKA_RTD_START_OFFSET:${KAFKA_CONSUMER_CONFIG_START_OFFSET:earliest}}
              autoCommitOffset: false
              ackMode: MANUAL_IMMEDIATE
              ackTime: ${KAFKA_RTD_ACK_MILLIS:500}
              standardHeaders: ${KAFKA_RTD_STANDARD_HEADERS:${KAFKA_CONSUMER_CONFIG_STANDARD_HEADERS:both}}
              configuration:
                max.poll:
                  records: ${KAFKA_RTD_MAX_POLL_SIZE:${KAFKA_CONSUMER_CONFIG_MAX_POLL_SIZE:500}}
                  interval.ms: ${KAFKA_RTD_INTERVAL_TIMEOUT_MS:${KAFKA_CONFIG_MAX_POLL_INTERVAL_TIMEOUT_MS:300000}}
                connections.max.idle.ms: ${KAFKA_RTD_CONNECTIONS_MAX_IDLE_MS:${KAFKA_CONSUMER_CONFIG_CONNECTIONS_MAX_IDLE_MS:180000}}
                socket.connection.setup.timeout:
                  max.ms: ${KAFKA_RTD_CONNECTION_TIMEOUT_MAX_MS:${KAFKA_CONSUMER_CONFIG_CONNECTION_TIMEOUT_MAX_MS:200000}}
                  ms: ${KAFKA_RTD_CONNECTION_TIMEOUT_MS:${KAFKA_CONSUMER_CONFIG_CONNECTION_TIMEOUT_MS:100000}}
          trxProcessorOut-out-0:
            producer:
              configuration:
                client.id: trxProcessor-userid-splitter
                connections.max.idle.ms: ${KAFKA_TRANSACTION_USER_ID_SPLITTER_CONNECTION_MAX_IDLE_TIME:180000}
                retry.backoff.ms: ${KAFKA_TRANSACTION_USER_ID_SPLITTER_KAFKA_RETRY_MS:${KAFKA_RETRY_MS:10000}}
                linger.ms: ${KAFKA_TRANSACTION_USER_ID_SPLITTER_LINGER_MS:${KAFKA_LINGER_MS:2}}
                batch.size: ${KAFKA_TRANSACTION_USER_ID_SPLITTER_BATCH_SIZE:${KAFKA_BATCH_SIZE:16384}}
          trxRejectedProducer-out-0:
            producer:
              configuration:
                client.id: trxProcessor-userid-splitter-rejected-transaction
                connections.max.idle.ms: ${KAFKA_TRANSACTION_CONNECTION_MAX_IDLE_TIME:180000}
                retry.backoff.ms: ${KAFKA_TRANSACTION_KAFKA_RETRY_MS:${KAFKA_RETRY_MS:10000}}
                linger.ms: ${KAFKA_TRANSACTION_LINGER_MS:${KAFKA_LINGER_MS:2}}
                batch.size: ${KAFKA_TRANSACTION_BATCH_SIZE:${KAFKA_BATCH_SIZE:16384}}
          errors-out-0:
            producer:
              configuration:
                client.id: trxProcessor-userid-splitter-errors
                connections.max.idle.ms: ${KAFKA_ERRORS_CONNECTION_MAX_IDLE_TIME:180000}
                retry.backoff.ms: ${KAFKA_ERRORS_KAFKA_RETRY_MS:${KAFKA_RETRY_MS:10000}}
                linger.ms: ${KAFKA_ERRORS_LINGER_MS:${KAFKA_LINGER_MS:2}}
                batch.size: ${KAFKA_ERRORS_BATCH_SIZE:${KAFKA_BATCH_SIZE:16384}}
  data:
    mongodb:
      uri: ${MONGODB_URI}
      database: ${MONGODB_DBNAME:idpay}
      # custom configured properties
      config:
        connectionPool:
          maxSize: ${MONGODB_CONNECTIONPOOL_MAX_SIZE:100}
          minSize: ${MONGODB_CONNECTIONPOOL_MIN_SIZE:5}
          maxWaitTimeMS: ${MONGODB_CONNECTIONPOOL_MAX_WAIT_MS:120000}
          maxConnectionLifeTimeMS: ${MONGODB_CONNECTIONPOOL_MAX_CONNECTION_LIFE_MS:0}
          maxConnectionIdleTimeMS: ${MONGODB_CONNECTIONPOOL_MAX_CONNECTION_IDLE_MS:120000}
          maxConnecting: ${MONGODB_CONNECTIONPOOL_MAX_CONNECTING:2}

management.endpoints:
  web:
    exposure.include: info, health

logging:
  level:
    root: ${LOG_LEVEL_ROOT:INFO}
    it.gov.pagopa: ${LOG_LEVEL_PAGOPA:INFO}
    it.gov.pagopa.common.reactive.kafka.consumer: ${LOG_LEVEL_BASE_KAFKA_CONSUMER:INFO}
    it.gov.pagopa.splitter: ${LOG_LEVEL_SPLITTER:INFO}
    org.springframework.integration: ${LOG_LEVEL_SPRING_INTEGRATION:INFO}
    org.springframework.security: ${LOG_LEVEL_SPRING_SECURITY:INFO}
    org.springframework.ws: ${LOG_LEVEL_SPRING_WS:INFO}
    org.springframework.cloud: ${LOG_LEVEL_SPRING_CLOUD:WARN}
    org.springframework.data: ${LOG_LEVEL_SPRING_DATA:INFO}
    org.springframework.hateoas: ${LOG_LEVEL_SPRING_HATEOAS:INFO}
    org.springframework.boot: ${LOG_LEVEL_SPRING_BOOT:INFO}
    org.springframework.kafka: ${LOG_LEVEL_SPRING_KAFKA:INFO}
    org.springframework.batch: ${LOG_LEVEL_SPRING_BATCH:INFO}
    io.swagger: ${LOG_LEVEL_IO_SWAGGER:WARN}
    javax.persistence: ${LOG_LEVEL_JAVAX_PERSISTENCE:INFO}
    org.hibernate: ${LOG_LEVEL_ORG_HIBERNATE:INFO}
    org.mongodb.driver: ${LOG_LEVEL_MONGODB_DRIVER:WARN}

app:
  reward-rule:
    # if true, it will try to build each rule singularly, but this will take more time
    online-syntax-check: ${REWARD_RULE_BUILD_ONLINE_SYNTAX_CHECK:false}
    # the delay after which it will fetch all the rules and compile them
    build-delay-duration: ${REWARD_RULE_BUILD_DELAY_DURATION:PT1S} # each second
    rule-engine:
      # if exit immediately at the first condition failed
      short-circuit-conditions: ${REWARD_RULE_SHORT_CIRCUIT:false}
  filter:
    mccExcluded: ${MCC_EXCLUDED:4784,6010,6011,7995,9222,9311}
  rules:
    cache:
      refresh-ms-rate: ${CACHE_REFRESH_MS_RATE:10000}
  threads:
    schedule-max-number: ${THREADS_SCHEDULE_MAX_NUMBER:1}